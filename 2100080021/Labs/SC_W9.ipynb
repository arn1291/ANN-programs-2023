{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KAAoAnz5pEcG"
      },
      "outputs": [],
      "source": [
        "import torch as tc\n",
        "import torch.nn as nn\n",
        "\n",
        "class FFN(nn.Module):\n",
        "  def __init__(self, inp, hidden, ops):\n",
        "    super().__init__()\n",
        "    self.lin1 = nn.Linear(inp, hidden)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    self.lin2 = nn.Linear(hidden, ops)\n",
        "  def forward(self, x):\n",
        "    x = self.lin1(x)\n",
        "    x = self.sig(x)\n",
        "    x = self.lin2(x)\n",
        "    return x\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 1\n",
        "output_size = 1\n",
        "\n",
        "model = FFN(input_size, hidden_size, output_size)\n",
        "\n",
        "data = tc.randn(20, input_size)\n",
        "# print(data)\n",
        "datax=tc.tensor([[1., 1.], [1., -1], [-1., 1.], [-1, -1]])\n",
        "datay = tc.tensor([-1., 1., 1., -1.])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Back Propagation"
      ],
      "metadata": {
        "id": "s6MfzJYgsLs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in datax:\n",
        "  print(model(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha15XM9TsKwl",
        "outputId": "fa4a3018-f319-47e8-fc65-f1de045a6a2a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.2612], grad_fn=<AddBackward0>)\n",
            "tensor([-1.4598], grad_fn=<AddBackward0>)\n",
            "tensor([-1.0180], grad_fn=<AddBackward0>)\n",
            "tensor([-1.1977], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With training"
      ],
      "metadata": {
        "id": "z8d-onOhsPmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "mseloss = nn.MSELoss()\n",
        "optimizer = tc.optim.Adam(model.parameters(), lr = 0.03)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range(4):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    yhat = model(datax[i])\n",
        "\n",
        "    loss = mseloss(yhat, datay[i])\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%100==0:\n",
        "      print(f\"loss = {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgZtVtgXsPAN",
        "outputId": "68ed28ae-94f2-43ef-cc53-bbf1b77f54b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.06820685416460037\n",
            "loss = 5.774493217468262\n",
            "loss = 3.806204080581665\n",
            "loss = 0.006786513142287731\n",
            "loss = 1.0057238340377808\n",
            "loss = 1.003869652748108\n",
            "loss = 0.9983976483345032\n",
            "loss = 1.007826566696167\n",
            "loss = 1.0065325498580933\n",
            "loss = 1.0000817775726318\n",
            "loss = 1.003781795501709\n",
            "loss = 1.004949927330017\n",
            "loss = 0.8933963179588318\n",
            "loss = 0.3094491958618164\n",
            "loss = 1.2683459520339966\n",
            "loss = 0.8830332159996033\n",
            "loss = 0.4592752456665039\n",
            "loss = 0.00035920587833970785\n",
            "loss = 1.7820621728897095\n",
            "loss = 0.45855069160461426\n",
            "loss = 0.4513002038002014\n",
            "loss = 5.3857431339565665e-05\n",
            "loss = 1.784401535987854\n",
            "loss = 0.4506608843803406\n",
            "loss = 0.44913750886917114\n",
            "loss = 1.677454201853834e-05\n",
            "loss = 1.7844961881637573\n",
            "loss = 0.44849222898483276\n",
            "loss = 0.4481489956378937\n",
            "loss = 6.868365289847134e-06\n",
            "loss = 1.7844678163528442\n",
            "loss = 0.44749483466148376\n",
            "loss = 0.4475972354412079\n",
            "loss = 3.251384896429954e-06\n",
            "loss = 1.7844254970550537\n",
            "loss = 0.44693616032600403\n",
            "loss = 0.4472527801990509\n",
            "loss = 1.6835932683534338e-06\n",
            "loss = 1.78438401222229\n",
            "loss = 0.4465866982936859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in datax:\n",
        "  print(model(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zywn2ZRPs6U-",
        "outputId": "32f34ded-7feb-4e4e-f005-193ab661cf9d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3314], grad_fn=<AddBackward0>)\n",
            "tensor([1.0011], grad_fn=<AddBackward0>)\n",
            "tensor([-0.3320], grad_fn=<AddBackward0>)\n",
            "tensor([-0.3314], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}